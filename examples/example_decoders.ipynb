{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# DeepSynergy imports\n",
    "from deepsynergy import decoders\n",
    "from deepsynergy.utils_training import train_decoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder sanity-check notebook\n",
    "\n",
    "Each section constructs a *synthetic* conditional distribution $p(x \\mid z)$, then trains the corresponding DeepSynergy **decoder** to reproduce that distribution.\n",
    "\n",
    "If training succeeds, the average cross-entropy returned by the decoder should match the analytic conditional entropy $H(X \\mid Z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 · BinaryDecoder — binary-symmetric channel\n",
    "\n",
    "* $Z \\in \\{0,1\\}$ with $\\Pr(Z = 1) = 0.5$  \n",
    "* A bit-flip occurs with probability $\\varepsilon$\n",
    "\n",
    "The conditional entropy is\n",
    "\n",
    "$$\n",
    "H(X \\mid Z)\\;=\\;\n",
    "-\\varepsilon \\,\\log_2 \\varepsilon \\;-\\; (1-\\varepsilon)\\,\\log_2(1-\\varepsilon).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.25it/s, loss=[0.460641]] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X|Z)  analytic : 0.469 bits\n",
      "H(X|Z)  decoder  : 0.461 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "samples   = 5_000\n",
    "epsilon   = 0.10    # flip probability\n",
    "\n",
    "# Analytical H(X|Z)\n",
    "H_theory  = -(epsilon*np.log2(epsilon) + (1-epsilon)*np.log2(1-epsilon))\n",
    "\n",
    "# Synthetic data\n",
    "Z = np.random.randint(0, 2, size=(samples, 1))\n",
    "X = (Z ^ (np.random.rand(samples, 1) < epsilon)).astype(np.float32)\n",
    "\n",
    "Z = torch.FloatTensor(Z)\n",
    "X = torch.FloatTensor(X)\n",
    "dataloader = DataLoader(TensorDataset(Z, X), batch_size=samples)\n",
    "\n",
    "# Decoder\n",
    "decoder = decoders.BinaryDecoder(\n",
    "    nn.Sequential(\n",
    "        nn.Linear(1, 8), nn.SELU(),\n",
    "        nn.Linear(8, 8), nn.SELU(),\n",
    "        nn.Linear(8, 1)\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "optim = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "decoder_results = train_decoder(\n",
    "    model       = decoder,\n",
    "    dataloader  = dataloader,\n",
    "    optimizer   = optim,\n",
    "    show_progress = True,\n",
    "    device      = device,\n",
    "    epochs      = 1000\n",
    ")\n",
    "\n",
    "H_decoder = decoder_results['loss'][0]\n",
    "\n",
    "print(f\"H(X|Z)  analytic : {H_theory:.3f} bits\")\n",
    "print(f\"H(X|Z)  decoder  : {H_decoder:.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 · CategoricalDecoder — $N$-ary symmetric channel\n",
    "\n",
    "* $Z$ is uniform on $\\{0,\\dots,N-1\\}$.  \n",
    "* With probability $\\varepsilon$ the output class is replaced\n",
    "  by a random *wrong* class.\n",
    "\n",
    "The entropy is\n",
    "\n",
    "$$\n",
    "H(X \\mid Z)=\n",
    "-(1-\\varepsilon)\\,\\log_2(1-\\varepsilon)\n",
    "-\\varepsilon\\,\\log_2\\!\\left(\\frac{\\varepsilon}{N-1}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:43<00:00, 23.22it/s, loss=[1.205383]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X|Z)  analytic : 1.122 bits\n",
      "H(X|Z)  decoder  : 1.205 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "samples = 5_000\n",
    "N = 5          # number of classes\n",
    "epsilon = 0.20 # error probability\n",
    "\n",
    "# Analytical H(X|Z)\n",
    "H_theory = -(1 - epsilon) * np.log2(1 - epsilon) - epsilon * np.log2(epsilon / (N - 1))\n",
    "\n",
    "# Synthetic data\n",
    "Z = np.random.randint(N, size=(samples, 1))\n",
    "X = Z.copy()\n",
    "flip = np.random.rand(samples, 1) < epsilon\n",
    "X[flip] = (Z[flip] + np.random.randint(1, N, size=flip.sum())) % N\n",
    "\n",
    "Z = torch.FloatTensor(Z)\n",
    "X = torch.FloatTensor(X)\n",
    "dataloader = DataLoader(TensorDataset(Z, X), batch_size=samples)\n",
    "\n",
    "# Decoder\n",
    "decoder = decoders.CategoricalDecoder(\n",
    "    nn.Sequential(\n",
    "        nn.Linear(1, 8), nn.SELU(),\n",
    "        nn.Linear(8, 16), nn.SELU(),\n",
    "        nn.Linear(16, 8), nn.SELU(),\n",
    "        nn.Linear(8, N)\n",
    "    ),\n",
    "    num_classes = N,\n",
    ").to(device)\n",
    "\n",
    "optim = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "decoder_results = train_decoder(\n",
    "    model       = decoder,\n",
    "    dataloader  = dataloader,\n",
    "    optimizer   = optim,\n",
    "    show_progress = True,\n",
    "    device      = device,\n",
    "    epochs      = 1000,\n",
    ")\n",
    "\n",
    "H_decoder = decoder_results['loss'][0]\n",
    "\n",
    "print(f\"H(X|Z)  analytic : {H_theory:.3f} bits\")\n",
    "print(f\"H(X|Z)  decoder  : {H_decoder:.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 · GaussianDecoder — scale depends on $|Z|$\n",
    "\n",
    "* $Z \\sim \\mathcal N(0,1)$  \n",
    "* $X \\mid Z=z \\sim \\mathcal N\\!\\bigl(0,\\, z^{2}\\bigr)$\n",
    "\n",
    "The differential entropy is\n",
    "\n",
    "$$\n",
    "H(X \\mid Z)\n",
    "= \\tfrac12\\log_2(2\\pi e)\n",
    "- \\tfrac12(\\gamma+\\log 2)/\\log 2\n",
    "\\;\\approx\\; 1.131\\ \\text{bits},\n",
    "$$\n",
    "\n",
    "where $\\gamma$ is the Euler–Mascheroni constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:44<00:00, 22.23it/s, loss=[1.2163494]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X|Z)  analytic : 1.131 bits\n",
      "H(X|Z)  decoder  : 1.216 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "samples = 5_000\n",
    "\n",
    "# Analytical H(X|Z)  (bits)\n",
    "H_theory = (\n",
    "    0.5 * np.log(2 * np.pi * np.e)           # ½ log(2πe)\n",
    "    - 0.5 * (np.log(2) + np.euler_gamma)     # −½(γ + log 2)\n",
    ") / np.log(2)\n",
    "\n",
    "# Synthetic data\n",
    "Z = np.random.randn(samples, 1)\n",
    "X = np.random.randn(samples, 1) * np.abs(Z)          # σ = |Z|\n",
    "\n",
    "Z = torch.FloatTensor(Z)\n",
    "X = torch.FloatTensor(X)\n",
    "dataloader = DataLoader(TensorDataset(Z, X), batch_size=samples)\n",
    "\n",
    "# Decoder\n",
    "decoder = decoders.GaussianDecoder(\n",
    "    nn.Sequential(\n",
    "        nn.Linear(1, 8), nn.SELU(),\n",
    "        nn.Linear(8, 8), nn.SELU(),\n",
    "    ),\n",
    "    output_dim = 1,\n",
    ").to(device)\n",
    "\n",
    "optim = torch.optim.Adam(decoder.parameters(), lr=3e-3)\n",
    "\n",
    "decoder_results = train_decoder(\n",
    "    model         = decoder,\n",
    "    dataloader    = dataloader,\n",
    "    optimizer     = optim,\n",
    "    show_progress = True,\n",
    "    device        = device,\n",
    "    epochs        = 1_000,\n",
    ")\n",
    "\n",
    "H_decoder = decoder_results['loss'][0]\n",
    "\n",
    "print(f\"H(X|Z)  analytic : {H_theory:.3f} bits\")\n",
    "print(f\"H(X|Z)  decoder  : {H_decoder:.3f} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 · GaussianMixtureDecoder — Laplace scale from $Z$\n",
    "\n",
    "* $Z \\sim \\mathrm{Exp}(1)$  \n",
    "* $X \\mid Z=z \\sim \\mathrm{Laplace}(0,\\, z)$\n",
    "\n",
    "Exact entropy:\n",
    "\n",
    "$$\n",
    "H(X \\mid Z)=\n",
    "\\bigl[1+\\log 2-\\gamma\\bigr]/\\log 2\n",
    "\\;\\approx\\; 1.608\\ \\text{bits}.\n",
    "$$\n",
    "\n",
    "A mixture with $K=5$ Gaussian components should approximate this well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.34it/s, loss=[1.6496264]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(X|Z)  analytic : 1.610 bits\n",
      "H(X|Z)  decoder  : 1.650 bits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "samples        = 5_000\n",
    "K              = 5        # number of mixture components\n",
    "\n",
    "# Analytical H(X|Z)  (bits)\n",
    "H_theory = (1 + np.log(2) - np.euler_gamma) / np.log(2)\n",
    "\n",
    "# Synthetic data\n",
    "Z = np.random.exponential(scale=1.0, size=(samples, 1))\n",
    "X = np.random.laplace(loc=0.0, scale=Z)               # Laplace(scale = Z)\n",
    "\n",
    "Z = torch.FloatTensor(Z)\n",
    "X = torch.FloatTensor(X)\n",
    "dataloader = DataLoader(TensorDataset(Z, X), batch_size=samples)\n",
    "\n",
    "# Decoder\n",
    "decoder = decoders.GaussianMixtureDecoder(\n",
    "    nn.Sequential(\n",
    "        nn.Linear(1, 8),  nn.SELU(),\n",
    "        nn.Linear(8, 16), nn.SELU(),\n",
    "        nn.Linear(16, 8), nn.SELU(),\n",
    "    ),\n",
    "    output_dim     = 1,\n",
    "    num_components = K,\n",
    ").to(device)\n",
    "\n",
    "optim = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "\n",
    "decoder_results = train_decoder(\n",
    "    model         = decoder,\n",
    "    dataloader    = dataloader,\n",
    "    optimizer     = optim,\n",
    "    show_progress = True,\n",
    "    device        = device,\n",
    "    epochs        = 1_000,\n",
    ")\n",
    "\n",
    "H_decoder = decoder_results['loss'][0]\n",
    "\n",
    "print(f\"H(X|Z)  analytic : {H_theory:.3f} bits\")\n",
    "print(f\"H(X|Z)  decoder  : {H_decoder:.3f} bits\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
